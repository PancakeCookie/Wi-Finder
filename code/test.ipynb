{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "load images ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:18<00:00,  1.31s/it]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "load images ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = '/opt/ml/upstage_OCR/code/saved/unet_focal/model.pt'\n",
    "state_dict_path = '/opt/ml/upstage_OCR/code/saved/unet_focal/last.pt'\n",
    "\n",
    "model = torch.load(model_path)\n",
    "model.load_state_dict(torch.load(state_dict_path))\n",
    "\n",
    "ann_path = '/opt/ml/upstage_OCR/Data set/annotations/general_00_10.json'\n",
    "ann_path_val = '/opt/ml/upstage_OCR/Data set/annotations/general_46_60.json'\n",
    "ocr_url = \"http://118.222.179.32:30000/ocr/\"\n",
    "image_root = '/opt/ml/upstage_OCR/Data set/real data/general'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "transform = A.Compose([\n",
    "    A.Resize(512,512),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_dataset = dataset.WifiDataset_segmentation(ann_path,ocr_url,image_root,transform=transform)\n",
    "val_dataset = dataset.WifiDataset_segmentation(ann_path_val,ocr_url,image_root,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True,\n",
    "                                           collate_fn=collate_fn)\n",
    "val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=4,\n",
    "                                           shuffle=True,\n",
    "                                           collate_fn=collate_fn)\n",
    "\n",
    "x,y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 31.75 GiB total capacity; 30.36 GiB already allocated; 197.50 MiB free; 30.42 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/upstage_OCR/code/test.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.245/opt/ml/upstage_OCR/code/test.ipynb#ch0000003vscode-remote?line=2'>3</a>\u001b[0m t \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mCompose(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.245/opt/ml/upstage_OCR/code/test.ipynb#ch0000003vscode-remote?line=3'>4</a>\u001b[0m     [torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mToPILImage()]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.245/opt/ml/upstage_OCR/code/test.ipynb#ch0000003vscode-remote?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.245/opt/ml/upstage_OCR/code/test.ipynb#ch0000003vscode-remote?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.245/opt/ml/upstage_OCR/code/test.ipynb#ch0000003vscode-remote?line=7'>8</a>\u001b[0m image \u001b[39m=\u001b[39m model(torch\u001b[39m.\u001b[39;49mstack(x)\u001b[39m.\u001b[39;49mto(device))[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.245/opt/ml/upstage_OCR/code/test.ipynb#ch0000003vscode-remote?line=8'>9</a>\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(image,dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.218.245/opt/ml/upstage_OCR/code/test.ipynb#ch0000003vscode-remote?line=10'>11</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=724'>725</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=725'>726</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=726'>727</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=727'>728</a>\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=728'>729</a>\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=729'>730</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=730'>731</a>\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/upstage_OCR/code/model.py:60\u001b[0m, in \u001b[0;36mUNetPlusPlus.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/ml/upstage_OCR/code/model.py?line=57'>58</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='file:///opt/ml/upstage_OCR/code/model.py?line=58'>59</a>\u001b[0m     seg_outputs \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='file:///opt/ml/upstage_OCR/code/model.py?line=59'>60</a>\u001b[0m     x0_0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv0_0(x)\n\u001b[1;32m     <a href='file:///opt/ml/upstage_OCR/code/model.py?line=60'>61</a>\u001b[0m     x1_0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1_0(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(x0_0))\n\u001b[1;32m     <a href='file:///opt/ml/upstage_OCR/code/model.py?line=61'>62</a>\u001b[0m     x0_1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv0_1(torch\u001b[39m.\u001b[39mcat([x0_0, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mUp[\u001b[39m0\u001b[39m](x1_0)], \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=724'>725</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=725'>726</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=726'>727</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=727'>728</a>\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=728'>729</a>\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=729'>730</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=730'>731</a>\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/upstage_OCR/code/model.py:16\u001b[0m, in \u001b[0;36mconv_block_nested.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/ml/upstage_OCR/code/model.py?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='file:///opt/ml/upstage_OCR/code/model.py?line=14'>15</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[0;32m---> <a href='file:///opt/ml/upstage_OCR/code/model.py?line=15'>16</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn1(x)\n\u001b[1;32m     <a href='file:///opt/ml/upstage_OCR/code/model.py?line=16'>17</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(x)\n\u001b[1;32m     <a href='file:///opt/ml/upstage_OCR/code/model.py?line=18'>19</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=724'>725</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=725'>726</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=726'>727</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=727'>728</a>\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=728'>729</a>\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=729'>730</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=730'>731</a>\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:131\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=123'>124</a>\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=125'>126</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=126'>127</a>\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=127'>128</a>\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=128'>129</a>\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=129'>130</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=130'>131</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=131'>132</a>\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=132'>133</a>\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=133'>134</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=134'>135</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=135'>136</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, bn_training, exponential_average_factor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2056\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/functional.py?line=2052'>2053</a>\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/functional.py?line=2053'>2054</a>\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/functional.py?line=2055'>2056</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/functional.py?line=2056'>2057</a>\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var,\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/functional.py?line=2057'>2058</a>\u001b[0m     training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/torch/nn/functional.py?line=2058'>2059</a>\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 31.75 GiB total capacity; 30.36 GiB already allocated; 197.50 MiB free; 30.42 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "t = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToPILImage()]\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "image = model(torch.stack(x).to(device))[0]\n",
    "out = torch.argmax(image,dim=0)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(t(out*0.3))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6104, 0.5448, 0.5177,  ..., 0.5186, 0.5394, 0.5987],\n",
       "        [0.5466, 0.4456, 0.4305,  ..., 0.4332, 0.4446, 0.5250],\n",
       "        [0.5155, 0.4400, 0.4282,  ..., 0.4373, 0.4399, 0.5060],\n",
       "        ...,\n",
       "        [0.6759, 0.6486, 0.6473,  ..., 0.6399, 0.6445, 0.6651],\n",
       "        [0.6725, 0.6407, 0.6349,  ..., 0.6272, 0.6341, 0.6652],\n",
       "        [0.6586, 0.6294, 0.6246,  ..., 0.6085, 0.6155, 0.6635]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
